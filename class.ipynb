{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-input":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport skimage\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true,"scrolled":false},"cell_type":"code","source":"#Load images with numpy\nimport csv\n\n        \n        \nimages = np.load('../input/f2018-hand-drawn-pictures/train_images.npy', encoding=\"latin1\")\ntest_images = np.load('../input/f2018-hand-drawn-pictures/test_images.npy', encoding=\"latin1\")\nlabels=[]\nwith open('../input/f2018-hand-drawn-pictures/train_labels.csv') as f:\n    reader = csv.reader(f, delimiter=',')\n    for ln in reader:\n        labels.append(ln)\n#create a y array target\nlabels = np.array(labels[1:])\ntarget = labels[:,1]\nprint(target)\nprint(test_images.shape)\ntarget_extend = np.repeat(target, 4)\nprint(len(target_extend))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"12d980fe45174518f75c649ae8aa8b55ebf2a908"},"cell_type":"code","source":"import skimage\nfrom skimage.restoration import estimate_sigma\nfrom skimage.transform import rotate\nimport cv2 as cv\nfrom scipy import ndimage\n#Reshaping image to 100x100\nimage_list_extend = []\nimage_list_test = []\nimage_list = []\n#doing data augmentation:\nfor im in images:\n    temp = im[1].reshape(100,100)\n    temp2 = np.fliplr(temp) #flipping left-right\n    temp3 = np.flipud(temp) #flipping up/down\n    temp4 = rotate(temp, angle=45, mode='reflect') \n    \n    image_list_extend.append(temp)\n    image_list_extend.append(temp2)\n    image_list_extend.append(temp3)\n    image_list_extend.append(temp4)    \n    \n    image_list.append(temp)\nprint(len(image_list))\nprint(len(image_list_extend))\n    \n#reshaping:\nfor im in test_images:\n    temp = im[1].reshape(100,100)\n    temp2 = temp\n    image_list_test.append(temp)\n    \n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"60aade8f586c7a88545189d864b49ce5545d35d7"},"cell_type":"code","source":"#a function that proccesses the image:\nimport cv2\nimport math\nimport scipy.stats\nimport os.path\nfrom tqdm import tqdm\n\n\ndef process(img_list):\n    img_ps = []\n    for i in tqdm(range(img_list.shape[0]), desc='image'):\n        \n        # convert to binary images\n        #im = img_list[i] / 255.\n        im = img_list[i]\n        im = im.astype(np.uint8)\n\n        # thresholding\n        ret,thresh = cv2.threshold(im,127,255,0)\n        \n        # find the contours from the image\n        im2, im_contours, h = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n        \n        c_radii = []\n        \n        # find the minimum enclosing circle of the contour, add the radius to list of radii\n        for contour in im_contours:\n            _cc, radius = cv2.minEnclosingCircle(contour)\n            c_radii.append(radius)\n\n        # find maximum radii from list, which is the largest contour in the image\n        sort_radii = sorted(c_radii, reverse=True)\n        largest = c_radii.index(sort_radii[0])\n\n        # store only the largest contour from the image\n        cx, cy, cw, ch = cv2.boundingRect(im_contours[largest])\n        im2 = im[cy:cy + ch, cx:cx + cw]\n\n        # resize the image to a 32x32 array\n        im3 = cv2.resize(im2, (32, 32))\n        img_ps.append(im3)\n\n    return img_ps","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7c28b957f5599afcaac7825cd4456c52e801ae1d"},"cell_type":"code","source":"#apply the processsing to out train and test\nnp.set_printoptions(threshold=np.nan)\ntraining_ps = process(np.array(image_list))\ntrain_ps_extend = process(np.array(image_list_extend))\ntest_ps = process(np.array(image_list_test))\nX = np.array(training_ps)\nX_extend = np.array(train_ps_extend)\nX_test_im = np.array(test_ps)\nprint(X.shape)\nprint(X_test_im.shape)\nplt.imshow(test_ps[11])\n#plt.imshow(image_list_test[11])\n#print(training_ps[1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"92d12cd741a7f04c7c782b45f2b088ea1f8792c8"},"cell_type":"code","source":"#SVM baseline is here:","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b8ea3df82ff1862f4748692bcfe9cde9616889b0"},"cell_type":"code","source":"#splitting and flattening for SVM\nfrom sklearn.model_selection import train_test_split\nnew_images_train = []\nnew_images_test = []\nfor image in training_ps:\n    image = image.flatten()\n    new_images_train.append(image)\nnew_images_train  = np.array(new_images_train)    \n\n# for image in test_ps:\n#     image = image.flatten()\n#     new_images_test.append(image)\n# new_images_test = np.array(new_images_test) \n# print(new_images_test.shape)\n# print(new_images_train.shape)\n\nX_train_svm, X_test_svm, y_train_svm, y_test_svm = train_test_split(new_images_train, target)\nX_train_svm = np.array(X_train_svm)\nX_test_svm = np.array(X_test_svm)\n\ny_train_svm = np.array(y_train_svm)\ny_test_svm = np.array(y_test_svm)\nprint(X_train_svm.shape)\nprint(X_test_svm.shape)\nprint(y_train_svm.shape)\nprint(y_test_svm.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6c56c847eb0d506e82392c97d792ffd38211e702","scrolled":true},"cell_type":"code","source":"#SVM\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import accuracy_score, classification_report\n\nclf = LinearSVC(verbose=True, penalty='l2', loss='hinge', C=0.000001, tol=0.0001)\nclf.fit(X_train_svm, y_train_svm)\nSVM_prediction = clf.predict(X_test_svm)\nprint(\"SVC Accuracy :\", accuracy_score(y_test_svm, SVM_prediction))\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9e03b0052c62254fba20bd7c3f8331c9c9c5c54a"},"cell_type":"code","source":"#splitting for CNN\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(training_ps, target)\nX_train_extend, X_test_extend, y_train_extend, y_test_extend = train_test_split(train_ps_extend, target_extend)\nX_train = np.array(X_train)\nX_test = np.array(X_test)\n\nX_train_extend = np.array(X_train_extend)\nX_test_extend = np.array(X_test_extend)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_test.shape)\nprint(y_test.shape)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"774f30b9091b8c0feca2327c1d543762d3bc7887"},"cell_type":"code","source":"#Convolutional Neural network","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73cc7107b952b2737d39ba3cc92808ed960a6437"},"cell_type":"code","source":"from __future__ import print_function\nimport keras\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nimport matplotlib.pyplot as plt\n\nbatch_size = 128\nnum_classes = 31\nepochs = 100\n\n# input image dimensions\nimg_rows, img_cols = 32, 32\nX_train_extend = X_train_extend.reshape(X_train_extend.shape[0], 1, img_rows, img_cols)\nX_test_extend = X_test_extend.reshape(X_test_extend.shape[0], 1, img_rows, img_cols)\nX_test_im = X_test_im.reshape(X_test_im.shape[0], 1, img_rows, img_cols)\ninput_shape = (1, img_rows, img_cols)\n\nlbl_encode = LabelEncoder()\ny_lab_train = lbl_encode.fit_transform(y_train_extend)\ny_lab_test = lbl_encode.transform(y_test_extend)\n\ny_lab_train = y_lab_train.reshape(len(y_lab_train), 1)\ny_lab_test = y_lab_test.reshape(len(y_lab_test), 1)\n\nencoder = OneHotEncoder(sparse=False)\ny_encode_train = encoder.fit_transform(y_lab_train)\ny_encode_test = encoder.transform(y_lab_test)\n\n\nmodel = Sequential()\nmodel.add(Conv2D(32, (3, 3), padding='same',input_shape=input_shape, data_format = 'channels_first', activation = 'relu'))\nmodel.add(Conv2D(64, (3, 3), data_format = 'channels_first', activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size=(3, 3)))\nmodel.add(Dropout(0.3))\nmodel.add(Conv2D(64, (3, 3), padding='same', data_format = 'channels_first', activation = 'sigmoid'))\nmodel.add(Conv2D(64, (3, 3), activation = 'sigmoid'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='sigmoid'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\n\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam',metrics=['accuracy'])\nearlyStopping = EarlyStopping(monitor='val_acc', patience=10, verbose=0, mode='auto')\ncheckpoint = ModelCheckpoint('model-best.h5', verbose=1, monitor='val_acc',save_best_only='true', mode='auto') \nhistory = model.fit(X_train_extend, y_encode_train, batch_size=batch_size, epochs=epochs, verbose=1,callbacks=[earlyStopping, checkpoint], validation_data=(X_test_extend, y_encode_test))\nmodel.load_weights(filepath = 'model-best.h5')\nresult = model.evaluate(X_test_extend, y_encode_test, verbose=0)\nprint('Test loss:', result[0])\nprint('Test accuracy:', result[1])\n\n\n#bin_pred = model.predict_classes(X_test_im)\n# # # # # # # #print(bin_pred)\n#fin_pred = lbl_encode.inverse_transform(bin_pred)\n\n#CNN_predict = pd.DataFrame(columns=[\"Id\",\"Category\"])\n#CNN_predict[\"Id\"] = range(0,10000) \n# CNN_predict[\"Category\"] =  fin_pred\n# CNN_predict.to_csv(\"CNN7_submission.csv\", index=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"51973502976c88c1a0bd9d2f393c57b4011fc44b"},"cell_type":"code","source":"\n\nfrom __future__ import print_function\nimport keras\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Activation\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping\nfrom keras import backend as K\n\nbatch_size = 128\nnum_classes = 31\nepochs = 50\n\n# input image dimensions\nimg_rows, img_cols = 32, 32\nX_train_extend = X_train_extend.reshape(X_train_extend.shape[0], 1, img_rows, img_cols)\nX_test_extend = X_test_extend.reshape(X_test_extend.shape[0], 1, img_rows, img_cols)\nX_test_im = X_test_im.reshape(X_test_im.shape[0], 1, img_rows, img_cols)\ninput_shape = (1, img_rows, img_cols)\n\nlbl_encode = LabelEncoder()\ny_lab_train = lbl_encode.fit_transform(y_train_extend)\ny_lab_test = lbl_encode.transform(y_test_extend)\n\ny_lab_train = y_lab_train.reshape(len(y_lab_train), 1)\ny_lab_test = y_lab_test.reshape(len(y_lab_test), 1)\n\nencoder = OneHotEncoder(sparse=False)\ny_encode_train = encoder.fit_transform(y_lab_train)\ny_encode_test = encoder.transform(y_lab_test)\n#y_train = keras.utils.to_categorical(y_train, num_classes)\n#y_test = keras.utils.to_categorical(y_test, num_classes)\n\nmodel = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3, 3),\n                 activation='relu', \n                input_shape=input_shape, data_format = 'channels_first'))\nmodel.add(Conv2D(64, (3, 3), activation='sigmoid', data_format = 'channels_first'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='sigmoid'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation='softmax'))\n\nmodel.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.Adadelta(),\n              metrics=['accuracy'])\nearlyStopping = EarlyStopping(monitor='val_acc', patience=10, verbose=0, mode='auto')\ncheckpoint = ModelCheckpoint('model-{epoch:03d}.h5', verbose=1, monitor='val_acc',save_best_only='true', mode='auto') \n# model.fit(X_train_extend, y_encode_train, batch_size=batch_size, epochs=epochs, verbose=1,callbacks=[earlyStopping, checkpoint], validation_data=(X_test_extend, y_encode_test))\n# #model.load_weights(filepath = 'model-{epoch:03d}.h5')\n# score = model.evaluate(X_test_extend, y_encode_test, verbose=0)\n# print('Test loss:', score[0])\n# print('Test accuracy:', score[1])\n\n# bin_pred = model.predict_classes(X_test_im)\n# # #print(bin_pred)\n# fin_pred = lbl_encode.inverse_transform(bin_pred)\n\n# CNN_predict = pd.DataFrame(columns=[\"Id\",\"Category\"])\n# CNN_predict[\"Id\"] = range(0,10000) \n# CNN_predict[\"Category\"] =  fin_pred\n# CNN_predict.to_csv(\"CNN3_submission.csv\", index=False)\n\nprint(\"done-ish\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}